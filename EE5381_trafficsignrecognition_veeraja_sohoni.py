# -*- coding: utf-8 -*-
"""EE5381_TrafficSignRecognition_Veeraja_Sohoni.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I47i-MUd8jmDgr7Ocrl6OaTqbT4AxJZq
"""

!git clone https://bitbucket.org/jadslim/german-traffic-signs

!ls german-traffic-signs

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout, Flatten   #reduces overfitting =dropout
from keras.layers.convolutional import Conv2D, MaxPooling2D
import pickle #to unpickle the serialised character string data in the pickle files:test.p, train.p, valid.p
import pandas as pd
import random 
import cv2

np.random.seed(0)

#unpickling the data files
with open('german-traffic-signs/train.p', 'rb') as f:
      train_data = pickle.load(f)               
with open('german-traffic-signs/valid.p', 'rb') as f:
      valid_data = pickle.load(f)
with open('german-traffic-signs/test.p', 'rb') as f:
      test_data = pickle.load(f)
print(type(train_data))   

X_train, y_train = train_data['features'], train_data['labels']
X_valid, y_valid = valid_data['features'], valid_data['labels']
X_test, y_test = test_data['features'], test_data['labels']

#printing shapes of the datasets
print(X_train.shape)
print(X_valid.shape)
print(X_test.shape)

#asserting to check if the data is correctly imported

assert(X_train.shape[0] == y_train.shape[0]), "The number of images is not equal to the number of labels"
assert(X_valid.shape[0] == y_valid.shape[0]), "The number of images is not equal to the number of labels"
assert(X_test.shape[0] == y_test.shape[0]), "The number of images is not equal to the number of labels"
assert(X_train.shape[1:] == (32, 32, 3)), "The dimensions of the images are not 32X32X3"
assert(X_test.shape[1:] == (32, 32, 3)), "The dimensions of the images are not 32X32X3"
assert(X_valid.shape[1:] == (32, 32, 3)), "The dimensions of the images are not 32X32X3"

data = pd.read_csv('german-traffic-signs/signnames.csv')
print(data)

num_of_samples = []
 
cols = 5
num_classes = 43
 
fig, axs = plt.subplots(nrows=num_classes, ncols = cols, figsize=(5, 50))
fig.tight_layout()

for i in range(cols):
    for j, row in data.iterrows():
        x_selected = X_train[y_train == j]
        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected - 1)), :, :], cmap=plt.get_cmap('gray'))
        axs[j][i].axis("off")
        if i == 2:
            axs[j][i].set_title(str(j) + "_" + row["SignName"])
            num_of_samples.append(len(x_selected))
    
    #(index, Series)

print(num_of_samples)
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Distribution of the training dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")
#observation: non-uniform distribution of images

import cv2
plt.imshow(X_train[2000])
plt.axis("off")
print(X_train[2000].shape)
print(y_train[2000])

def grayscale(img):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img

def equalize(img):
  img = cv2.equalizeHist(img)
  return img

def preprocessing(img):
  img = grayscale(img)
  img = equalize(img)
  #use normalisation
  img = img/255
  return img

#passing dataset through this function
X_train = np.array(list(map(preprocessing, X_train)))
X_test = np.array(list(map(preprocessing, X_test)))
X_valid = np.array(list(map(preprocessing, X_valid)))

#plotting the entire dataset for visulaisation
plt.imshow(X_train[random.randint(0, len(X_train)-1)], cmap=plt.get_cmap("gray"))
plt.axis("off")
print(X_train.shape)

#reshaping the dataset to include the depth that is 1 dimension
X_train = X_train.reshape(34799, 32, 32, 1)
X_test = X_test.reshape(12630, 32, 32, 1)
X_valid = X_valid.reshape(4410, 32, 32, 1)

#data augmentation to increase number of image instances with added rotation and shifts/zooming
from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2,shear_range=0.1, rotation_range=10 )
datagen.fit(X_train)

batches = datagen.flow(X_train, y_train, batch_size=20)
X_batch, y_batch = next(batches)

fig, axs = plt.subplots(1, 15, figsize = (20, 5))
fig.tight_layout()

for i in range(15):
    axs[i].imshow(X_batch[i].reshape(32, 32), cmap=plt.get_cmap("gray"))
    axs[i].axis('off')

#new dimensions
print(X_train.shape)
print(X_test.shape)
print(X_valid.shape)

#one hot encoding to the y_labels to remove dependency
y_train = to_categorical(y_train, 43)
y_test = to_categorical(y_test, 43)
y_valid = to_categorical(y_valid, 43)

#leNet implementation 

def leNetmodified_model():
    model = Sequential()
    model.add(Conv2D(60, (5,5), input_shape=(32, 32, 1), activation='relu')) #adding first convolutional layer, improv #2 increasing no.of filters
    model.add(Conv2D(60, (5,5), activation='relu')) #improv #3: adding convolution layer
    model.add(MaxPooling2D(pool_size=(2,2)))#adding pooling layer for avoiding overfitting and scales down image, doesn't affects the depth
    
    model.add(Conv2D(30, (3,3), activation='relu'))  #another convolutional layer, depth=30
    model.add(Conv2D(30, (3,3), activation='relu')) #improv #3: adding convolution layer
    model.add(MaxPooling2D(pool_size=(2,2)))#another pooling layer
    #model.add(Dropout(0.5))#adding dropout layer improv #4
        
    model.add(Flatten())#flatten to format the data to fed into the fully connected layer
    model.add(Dense(500, activation='relu')) #adding dense/fully connected layer
    model.add(Dropout(0.5))#adding dropout layer, half the nodes are dropped for each update
    model.add(Dense(num_classes, activation='softmax'))#adding output layer

    #compile model
    model.compile(Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy']) #from lr=0.01 to lr= 0.001 update
    return model

model = leNetmodified_model()
print(model.summary())

#training model
#hist = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), batch_size=400, verbose=1, shuffle=1)

#fitting including the datagen improv #5
hist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=50), 
                           steps_per_epoch=695, epochs=15, validation_data=(X_valid, y_valid), shuffle=1)

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('Loss')
plt.xlabel('epoch')

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.legend(['training', 'validation'])
plt.title('Accuracy')
plt.xlabel('epoch')

#checking the score for the model will give the performance at a glance
score = model.evaluate(X_test, y_test, verbose=1)

print('Test Score:', score[0])
print('Accuracy:', score[1])

#fetching image for testing the code
 
import requests
from PIL import Image
url = 'https://c8.alamy.com/comp/J2MRAJ/german-road-sign-bicycles-crossing-J2MRAJ.jpg'
r = requests.get(url, stream=True)
img = Image.open(r.raw)
plt.imshow(img, cmap=plt.get_cmap('gray'))

#Preprocess image
 
img = np.asarray(img)
img = cv2.resize(img, (32, 32))
img = preprocessing(img)
plt.imshow(img, cmap = plt.get_cmap('gray'))
print(img.shape)
 
#Reshape for feeding to the neural network
 
img = img.reshape(1, 32, 32, 1)
 
#Test image
print("predicted sign: "+ str(model.predict_classes(img)))
#plotting probability
probab = ((model.predict_proba(img)))
probab = probab.flatten()
print(type(probab))
#"""
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), probab)
plt.title("Distribution of the probability")
plt.xlabel("Class number")
plt.ylabel("Probability amongst Dataset")
#"""